{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pd.read_csv('../data/pheno_final.tsv', sep='\\t')\n",
    "pheno = pheno.set_index('subject', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ase = pd.read_csv('ase.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvs = pd.read_csv('ASE rare CADD variants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark rare variants as ASE or not ASE\n",
    "\n",
    "pvs['ASE'] = 0\n",
    "for i, row in pvs.iterrows():\n",
    "    gene = row['Gene.refGene']\n",
    "    sub = row['Sample']\n",
    "    \n",
    "    if ase[(ase.subject == sub) & (ase.gene == gene)].shape[0] > 0:\n",
    "        pvs.at[i, 'ASE'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out variants without ASE\n",
    "\n",
    "pvs = pvs[pvs['ASE'] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_haps(haps):\n",
    "    haps_by_variants = []\n",
    "    \n",
    "    for j, row in haps.iterrows():\n",
    "        variants = row['variants']\n",
    "        haplotypeA = row['haplotypeA']\n",
    "        haplotypeB = row['haplotypeB']\n",
    "        aCount = row['aCount']\n",
    "        bCount = row['bCount']\n",
    "        blockGWPhase = row['blockGWPhase']\n",
    "        gwStat = row['gwStat']\n",
    "        \n",
    "        variants = variants.split(',')\n",
    "        haplotypeA = haplotypeA.split(',')\n",
    "        haplotypeB = haplotypeB.split(',')\n",
    "        for k in range(len(variants)):\n",
    "            haps_by_variants.append([j, variants[k], haplotypeA[k], haplotypeB[k],\n",
    "                                    aCount, bCount, blockGWPhase, gwStat])            \n",
    "\n",
    "\n",
    "            \n",
    "    cols = ['index', 'variant', 'haplotypeA', 'haplotypeB', 'aCount',\n",
    "            'bCount', 'blockGWPhase', 'gwStat']\n",
    "    haps_by_variants = pd.DataFrame(haps_by_variants, columns=cols)\n",
    "    haps_by_variants['chrom'] = haps_by_variants.variant.apply(lambda s: s.split('_')[0])\n",
    "    haps_by_variants['pos'] = haps_by_variants.variant.apply(lambda s: int(s.split('_')[1]))\n",
    "    haps_by_variants = haps_by_variants.set_index('pos', drop=False)\n",
    "    return haps_by_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvs['ASE'] = '.'\n",
    "\n",
    "for i, row in pvs.iterrows():\n",
    "    sub = row['Sample']\n",
    "    chrom = row['Chr']\n",
    "    chrom = chrom[3:]\n",
    "    pos = row['Pos']\n",
    "    allele = row['Alt']\n",
    "    ref_allele = row['Ref']\n",
    "\n",
    "    # load GENE AE hap file\n",
    "    haps = pd.read_csv('../../ase_no_replicates/output/{}.haplotypic_counts.txt'.format(sub), sep='\\t')\n",
    "    haps.contig = haps.contig.astype(str)\n",
    "        \n",
    "    # keep only nearby region\n",
    "    haps = haps[haps.contig == chrom]\n",
    "    haps = haps[haps.start > pos-100000]\n",
    "    haps = haps[haps.stop  < pos+100000]\n",
    "    if haps.shape[0] == 0:\n",
    "        pvs.at[i, 'ASE'] = 'not_in_geneae'\n",
    "        continue\n",
    "        \n",
    "    # split by variant\n",
    "    haps_by_variants = flatten_haps(haps)\n",
    "                \n",
    "    if pos not in haps_by_variants.pos:\n",
    "        pvs.at[i, 'ASE'] = 'not_in_geneae'\n",
    "        continue\n",
    "                        \n",
    "    hap_var = haps_by_variants.loc[pos]\n",
    "    aCount = hap_var['aCount']\n",
    "    bCount = hap_var['bCount']\n",
    "    if aCount == bCount:\n",
    "        pvs.at[i, 'ASE'] = 'same_allelic_counts'\n",
    "        continue\n",
    "\n",
    "    if aCount > bCount:\n",
    "        overexp_allele = hap_var['haplotypeA']\n",
    "    if bCount > aCount:\n",
    "        overexp_allele = hap_var['haplotypeB']\n",
    "\n",
    "    if overexp_allele == allele:\n",
    "        pvs.at[i, 'ASE'] = 'on_overexpressed_haplo'\n",
    "        continue\n",
    "    else:\n",
    "        pvs.at[i, 'ASE'] = 'on_underexpressed_haplo'\n",
    "        continue\n",
    "                \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "\n",
    "pvs.to_csv('cadd.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "on_underexpressed_haplo    122\n",
       "not_in_geneae               55\n",
       "on_overexpressed_haplo      25\n",
       "Name: ASE, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvs.ASE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 14)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvs.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "on_underexpressed_haplo    122\n",
    "not_used_by_phaser          55\n",
    "on_overexpressed_haplo      25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only those on overexpressed haplotype\n",
    "\n",
    "cadd = pvs[pvs['ASE'] == 'on_overexpressed_haplo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add annotations to ase\n",
    "\n",
    "ase['cadd_greater_than_25'] = ''\n",
    "\n",
    "for i, row in cadd.iterrows():\n",
    "    sub = row['Sample']\n",
    "    gene = row['Gene.refGene']\n",
    "    \n",
    "    subase = ase[(ase.subject == sub) & (ase.gene == gene)]\n",
    "    index= subase.index[0]\n",
    "    ase.at[index, 'cadd_greater_than_25'] = 'X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "\n",
    "ase.to_csv('ase_cadd_annotated.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
